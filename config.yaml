model:
  num_channels_1: 8
  num_channels_2: 16
  emb_dim: 128
  dropout: 0.25
  lr: 0.0005

data:
  batch_size: 64
  num_workers: 4
  padding: 2
  rotation: 15

training:
  max_epochs: 80
  patience: 5
  every_n_epochs: 1
